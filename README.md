# üå∏ Clasificaci√≥n de Flores con Transfer Learning

![Ejemplo de predicci√≥n](assets/predictions.png) <!-- T√∫ agregar√°s esta imagen -->
![Matriz de confusi√≥n](assets/confusion_matrix.png) <!-- T√∫ agregar√°s esta imagen -->

Este proyecto implementa un modelo de **clasificaci√≥n de im√°genes de flores** utilizando **transfer learning** con la arquitectura **EfficientNetB0** preentrenada en ImageNet. El objetivo es identificar correctamente cinco tipos de flores del dataset `tf_flowers` de TensorFlow Datasets.

---

## üéØ Objetivo

Desarrollar un modelo de visi√≥n por computadora capaz de clasificar im√°genes de flores con alta precisi√≥n, aprovechando modelos preentrenados y buenas pr√°cticas de fine-tuning, incluso con un conjunto de datos relativamente peque√±o (~3,600 im√°genes).

---

## üåº Clases del dataset

El dataset `tf_flowers` contiene **5 categor√≠as**:
- Diente de le√≥n (`dandelion`)
- Margarita (`daisy`)
- Tulip√°n (`tulips`)
- Girasol (`sunflowers`)
- Rosa (`roses`)

> ‚ö†Ô∏è El dataset presenta **desequilibrio de clases** (m√°s im√°genes de girasoles que de tulipanes, por ejemplo).

---

## üõ†Ô∏è Tecnolog√≠as utilizadas

- **Lenguaje**: Python 3.12
- **Framework**: TensorFlow 2.19 + Keras
- **Librer√≠as**:
  - `tensorflow_datasets` (para cargar el dataset)
  - `matplotlib` y `seaborn` (visualizaci√≥n)
  - `scikit-learn` (m√©tricas: matriz de confusi√≥n, reporte de clasificaci√≥n)
  - `numpy`

---

## üìÇ Estructura del c√≥digo

1. **Verificaci√≥n del entorno**  
   Se confirma la versi√≥n de Python, TensorFlow y la disponibilidad de GPU.

2. **Carga del dataset**  
   Se utiliza `tfds.load('tf_flowers')` para dividir los datos en:
   - 70% entrenamiento
   - 15% validaci√≥n
   - 15% prueba

3. **Preprocesamiento**  
   - Redimensi√≥n de im√°genes a **224√ó224 p√≠xeles** (entrada requerida por EfficientNetB0)
   - Conversi√≥n a `float32`
   - No se normaliza manualmente (EfficientNet incluye su propio preprocesamiento)
   - Configuraci√≥n de rendimiento: `cache()`, `shuffle()`, `batch()`, `prefetch()`

4. **Modelo con Transfer Learning**
   - Se carga **EfficientNetB0** preentrenado en ImageNet (`weights='imagenet'`)
   - Se congela el modelo base (`base_model.trainable = False`)
   - Se a√±aden capas personalizadas:
     - `GlobalAveragePooling2D()`
     - `Dropout(0.3)`
     - `Dense(128, activation='relu')`
     - `Dropout(0.2)`
     - `Dense(5, activation='softmax')` (una neurona por clase)

5. **Entrenamiento**
   - Optimizador: `Adam` con `learning_rate=0.001`
   - Funci√≥n de p√©rdida: `sparse_categorical_crossentropy`
   - M√©trica: `accuracy`
   - Callback: `EarlyStopping` (detiene si no mejora la p√©rdida en validaci√≥n durante 5 √©pocas)

6. **Evaluaci√≥n**
   - Precisi√≥n en conjunto de prueba: **94.55%**
   - Visualizaci√≥n de:
     - Curvas de entrenamiento vs validaci√≥n (precisi√≥n y p√©rdida)
     - Ejemplos de predicciones (correctas e incorrectas)
     - Matriz de confusi√≥n
     - Reporte de clasificaci√≥n (precisi√≥n, recall, F1-score por clase)

---

## üìà Resultados clave

- **Precisi√≥n final en prueba**: **94.55%**
- El modelo aprende r√°pidamente (m√°s del 90% de precisi√≥n desde la √©poca 2)
- Algunos errores ocurren entre clases visualmente similares (ej: margarita vs tulip√°n)

> üìå **T√∫ puedes insertar aqu√≠ una imagen de las curvas de entrenamiento**  
> ![Curvas de entrenamiento](assets/training_curves.png)

---

## üîç An√°lisis cr√≠tico

### ¬øPor qu√© se eligi√≥ EfficientNetB0?
- Excelente relaci√≥n **precisi√≥n/eficiencia**
- Menos par√°metros que ResNet50 ‚Üí menor riesgo de sobreajuste en datasets peque√±os
- Preentrenado en ImageNet ‚Üí transferencia de conocimiento visual robusta

### Principales desaf√≠os
1. **Desequilibrio de clases**: Algunas flores tienen muchas m√°s muestras.
2. **Variabilidad visual**: Fondos no controlados, iluminaci√≥n y √°ngulos diversos.
3. **Tama√±o limitado del dataset**: Solo ~3,600 im√°genes en total.

### Mejoras propuestas para producci√≥n
- ‚úÖ **Aumento de datos**: rotaci√≥n, zoom, volteo horizontal.
- ‚úÖ **Fine-tuning**: descongelar las √∫ltimas capas de EfficientNetB0 y reentrenar con LR bajo (ej. `1e-5`).
- ‚úÖ **Balanceo de clases**: usar `class_weight='balanced'` en `model.fit()`.
- ‚úÖ **Exportar a TensorFlow Lite**: para despliegue en dispositivos m√≥viles.
- ‚úÖ **Monitoreo continuo**: registrar m√©tricas en producci√≥n y reentrenar con nuevos datos.

---

## ‚ñ∂Ô∏è C√≥mo ejecutar el proyecto

1. Clona este repositorio:
   ```bash
   git clone https://github.com/EnzoGatica/clasificacion-flores.git
   cd clasificacion-flores